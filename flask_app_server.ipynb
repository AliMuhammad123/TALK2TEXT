{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import speech_recognition as sr \n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment  \n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import moviepy.editor as mp \n",
    "from moviepy.editor import VideoFileClip  \n",
    "from googletrans import Translator\n",
    "from gensim.summarization import summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "try: \n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "except ImportError: \n",
    "    print(\"PyTorch is not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yt1s.com - Trust Allah for everything  No matter what  Mufti Menk.mp4\n",
      "MoviePy - Writing audio in uploads\\test\\yt1s.com - Trust Allah for everything  No matter what  Mufti Menk.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:03:57] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:04:18] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2024 00:04:20] \"GET /api/translate_toen/first%20Allah%20for%20everything%20no%20matter%20what%20you%20lose%20you%20trust%20Allah%20you%20win%20you%20trust%20Allah%20you%20gain%20you%20trust%20Allah%20you%20have%20a%20problem%20you%20trust%20online%20things%20are%20not%20going%20your%20way%20you%20thank%20you%20even%20more%20and%20you%20talk%20to%20him%20that's%20a%20very%20good%20habit%20to%20talk%20to%20Allah%20and%20Allah%20knows%20it%20more%20than%20you%20do%20but%20it's%20good%20for%20you%20too%20like%20you%20know%20try%20to%20him%20tell%20him%20he%20knows%20but%20he%20wants%20to%20hear%20it%20from%20you%20as%20well%20it's%20like%20you%20want%20you%20making%20it%20you%20know%20it HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2024 00:04:21] \"POST /api/analyze-audio/first%20Allah%20for%20everything%20no%20matter%20what%20you%20lose%20you%20trust%20Allah%20you%20win%20you%20trust%20Allah%20you%20gain%20you%20trust%20Allah%20you%20have%20a%20problem%20you%20trust%20online%20things%20are%20not%20going%20your%20way%20you%20thank%20you%20even%20more%20and%20you%20talk%20to%20him%20that's%20a%20very%20good%20habit%20to%20talk%20to%20Allah%20and%20Allah%20knows%20it%20more%20than%20you%20do%20but%20it's%20good%20for%20you%20too%20like%20you%20know%20try%20to%20him%20tell%20him%20he%20knows%20but%20he%20wants%20to%20hear%20it%20from%20you%20as%20well%20it's%20like%20you%20want%20you%20making%20it%20you%20know%20it HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "127.0.0.1 - - [02/Apr/2024 00:08:29] \"POST /api/findtopic/first%20Allah%20for%20everything%20no%20matter%20what%20you%20lose%20you%20trust%20Allah%20you%20win%20you%20trust%20Allah%20you%20gain%20you%20trust%20Allah%20you%20have%20a%20problem%20you%20trust%20online%20things%20are%20not%20going%20your%20way%20you%20thank%20you%20even%20more%20and%20you%20talk%20to%20him%20that's%20a%20very%20good%20habit%20to%20talk%20to%20Allah%20and%20Allah%20knows%20it%20more%20than%20you%20do%20but%20it's%20good%20for%20you%20too%20like%20you%20know%20try%20to%20him%20tell%20him%20he%20knows%20but%20he%20wants%20to%20hear%20it%20from%20you%20as%20well%20it's%20like%20you%20want%20you%20making%20it%20you%20know%20it HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:08:57] \"POST /api/findSummary HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\92310\\AppData\\Roaming\\nltk_data...\n",
      "127.0.0.1 - - [02/Apr/2024 00:09:00] \"POST /api/sentiment/first%20Allah%20for%20everything%20no%20matter%20what%20you%20lose%20you%20trust%20Allah%20you%20win%20you%20trust%20Allah%20you%20gain%20you%20trust%20Allah%20you%20have%20a%20problem%20you%20trust%20online%20things%20are%20not%20going%20your%20way%20you%20thank%20you%20even%20more%20and%20you%20talk%20to%20him%20that's%20a%20very%20good%20habit%20to%20talk%20to%20Allah%20and%20Allah%20knows%20it%20more%20than%20you%20do%20but%20it's%20good%20for%20you%20too%20like%20you%20know%20try%20to%20him%20tell%20him%20he%20knows%20but%20he%20wants%20to%20hear%20it%20from%20you%20as%20well%20it's%20like%20you%20want%20you%20making%20it%20you%20know%20it HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3 css.mp4\n",
      "MoviePy - Writing audio in uploads\\test\\test3 css.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:10:51] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Proccessing Input........\n",
      "Converting to text........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:12:40] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2024 00:12:42] \"GET /api/translate_toen/I%20started%20my%20journey%20back%20in%202019%20after%20I%20had%20just%20graduated%20from%20fast%20and%20with%20a%20degree%20in%20Business%20Administration%20and%20I%20appeared%20in%20CSS%202020%20for%20my%20first%20attempt%20however%20I%20wasn't%20able%20to%20qualify%20the%20essay%20part%20which%20is%20why%20I%20appeared%20again%20in%20CSS%202021%20and%20fortunately%20Allah%20has%20been%20very%20kind%20to%20me%20and%20this%20time%20I%20did%20qualify%20so%20my%20Germany%20has%20also%20been%20a%20very%20long%20one%20tell%20me%20there%20is%20always%20an%20inspiration%20and%20when%20it%20comes%20to%20girls%20either%20decision%20inspiration%20of%20his%20father%20or%20mother%20what%20was%20your%20inspiration%20in%20this%20journey%20my%20inspiration%20was%20my%20grandfather%20my%20mother%20and%20my%20father%20I%20have%20with%20me%20these%20books%20that%20I%20brought%20to%20show%20that%20during%20my%20preparation%20Phase%20I%20had%20these%20three%20right%20next%20to%20my%20study%20table%20and%20I%20would%20look%20at%20them%20whenever%20times%20would%20get%20a%20for%20instance%20are%20this%20was%20the%20book%20that%20my%20mother%20purchased%20when%20she%20when%20she%20wanted%20to%20prepare%20for%20CSS%20and%20then%20these%20two%20books%20were%20purchased%20by%20my%20grandfather%20as%20you%20can%20see%20their%20very%20old%20books%20and%20this%20this%20book%20was%20published%20in%20Lucknow%20while%20this%20book%20came%20in%20the%20West%20Pakistan%20and%20these%20three%20books%20have%20kept%20me%20going%20when%20times%20got%20half%20when%20it%20was%20Difficult%20to%20move%20on%20I%20would%20just%20look%20at%20these%20books%20and%20I%20would%20just%20be%20inspired%20all%20over%20again%20so%20for%20me%20that%20inspiration%20was%20very%20tangible%20my%20mother%20and%20my%20grandfather%20are%20my%20grandfather%20is%20retired%20professor%20my%20mother%20is%20currently%20serving%20as%20an%20associate%20professor%20and%20I've%20been%20very%20lucky%20painting%20dogs%20record%20and%20we%20provide%20the%20source%20now%20let's%20move%20on%20to%20the%20final%20part%20let%20me%20go%20a%20little%20down%20let's%20put%20here%20I%20try%20and%20except%20block%20and%20let's%20declare%20a%20text%20that%20is%20equals%20to%20engine%20parts%20recognise%20underscore%20Google%20and%20we%20provide%20you%20after%20this%20let's%20print%20in%20the%20console%20over%20text%20and%20also%20we%20want%20to%20save%20in%20txt%20file%20so%20open%20we%20provide%20the%20name%20text%20from%20MP3%20txt%20and%20next%20we%20want%20to%20write%20the%20text%20in%20our%20new%20files%20and%20we%20provides%20the%20text%20going%20to%20exception%20block%20here%20and%20and%20don't%20forget%20that%20you%20can%20download%20the%20source%20code%20also%20don't%20forget%20to%20give%20these%20video%20like%20share%20it%20with%20your%20friends%20subscribe%20and%20activate%20the%20bell%20button%20to%20get%20notifications%20about%20new%20videos%20that%20come%20out%20and%20as%20always%20thank%20you%20for%20watching HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2024 00:12:44] \"POST /api/analyze-audio/I%20started%20my%20journey%20back%20in%202019%20after%20I%20had%20just%20graduated%20from%20fast%20and%20with%20a%20degree%20in%20Business%20Administration%20and%20I%20appeared%20in%20CSS%202020%20for%20my%20first%20attempt%20however%20I%20wasn't%20able%20to%20qualify%20the%20essay%20part%20which%20is%20why%20I%20appeared%20again%20in%20CSS%202021%20and%20fortunately%20Allah%20has%20been%20very%20kind%20to%20me%20and%20this%20time%20I%20did%20qualify%20so%20my%20Germany%20has%20also%20been%20a%20very%20long%20one%20tell%20me%20there%20is%20always%20an%20inspiration%20and%20when%20it%20comes%20to%20girls%20either%20decision%20inspiration%20of%20his%20father%20or%20mother%20what%20was%20your%20inspiration%20in%20this%20journey%20my%20inspiration%20was%20my%20grandfather%20my%20mother%20and%20my%20father%20I%20have%20with%20me%20these%20books%20that%20I%20brought%20to%20show%20that%20during%20my%20preparation%20Phase%20I%20had%20these%20three%20right%20next%20to%20my%20study%20table%20and%20I%20would%20look%20at%20them%20whenever%20times%20would%20get%20a%20for%20instance%20are%20this%20was%20the%20book%20that%20my%20mother%20purchased%20when%20she%20when%20she%20wanted%20to%20prepare%20for%20CSS%20and%20then%20these%20two%20books%20were%20purchased%20by%20my%20grandfather%20as%20you%20can%20see%20their%20very%20old%20books%20and%20this%20this%20book%20was%20published%20in%20Lucknow%20while%20this%20book%20came%20in%20the%20West%20Pakistan%20and%20these%20three%20books%20have%20kept%20me%20going%20when%20times%20got%20half%20when%20it%20was%20Difficult%20to%20move%20on%20I%20would%20just%20look%20at%20these%20books%20and%20I%20would%20just%20be%20inspired%20all%20over%20again%20so%20for%20me%20that%20inspiration%20was%20very%20tangible%20my%20mother%20and%20my%20grandfather%20are%20my%20grandfather%20is%20retired%20professor%20my%20mother%20is%20currently%20serving%20as%20an%20associate%20professor%20and%20I've%20been%20very%20lucky%20painting%20dogs%20record%20and%20we%20provide%20the%20source%20now%20let's%20move%20on%20to%20the%20final%20part%20let%20me%20go%20a%20little%20down%20let's%20put%20here%20I%20try%20and%20except%20block%20and%20let's%20declare%20a%20text%20that%20is%20equals%20to%20engine%20parts%20recognise%20underscore%20Google%20and%20we%20provide%20you%20after%20this%20let's%20print%20in%20the%20console%20over%20text%20and%20also%20we%20want%20to%20save%20in%20txt%20file%20so%20open%20we%20provide%20the%20name%20text%20from%20MP3%20txt%20and%20next%20we%20want%20to%20write%20the%20text%20in%20our%20new%20files%20and%20we%20provides%20the%20text%20going%20to%20exception%20block%20here%20and%20and%20don't%20forget%20that%20you%20can%20download%20the%20source%20code%20also%20don't%20forget%20to%20give%20these%20video%20like%20share%20it%20with%20your%20friends%20subscribe%20and%20activate%20the%20bell%20button%20to%20get%20notifications%20about%20new%20videos%20that%20come%20out%20and%20as%20always%20thank%20you%20for%20watching HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "127.0.0.1 - - [02/Apr/2024 00:13:12] \"POST /api/findtopic/I%20started%20my%20journey%20back%20in%202019%20after%20I%20had%20just%20graduated%20from%20fast%20and%20with%20a%20degree%20in%20Business%20Administration%20and%20I%20appeared%20in%20CSS%202020%20for%20my%20first%20attempt%20however%20I%20wasn't%20able%20to%20qualify%20the%20essay%20part%20which%20is%20why%20I%20appeared%20again%20in%20CSS%202021%20and%20fortunately%20Allah%20has%20been%20very%20kind%20to%20me%20and%20this%20time%20I%20did%20qualify%20so%20my%20Germany%20has%20also%20been%20a%20very%20long%20one%20tell%20me%20there%20is%20always%20an%20inspiration%20and%20when%20it%20comes%20to%20girls%20either%20decision%20inspiration%20of%20his%20father%20or%20mother%20what%20was%20your%20inspiration%20in%20this%20journey%20my%20inspiration%20was%20my%20grandfather%20my%20mother%20and%20my%20father%20I%20have%20with%20me%20these%20books%20that%20I%20brought%20to%20show%20that%20during%20my%20preparation%20Phase%20I%20had%20these%20three%20right%20next%20to%20my%20study%20table%20and%20I%20would%20look%20at%20them%20whenever%20times%20would%20get%20a%20for%20instance%20are%20this%20was%20the%20book%20that%20my%20mother%20purchased%20when%20she%20when%20she%20wanted%20to%20prepare%20for%20CSS%20and%20then%20these%20two%20books%20were%20purchased%20by%20my%20grandfather%20as%20you%20can%20see%20their%20very%20old%20books%20and%20this%20this%20book%20was%20published%20in%20Lucknow%20while%20this%20book%20came%20in%20the%20West%20Pakistan%20and%20these%20three%20books%20have%20kept%20me%20going%20when%20times%20got%20half%20when%20it%20was%20Difficult%20to%20move%20on%20I%20would%20just%20look%20at%20these%20books%20and%20I%20would%20just%20be%20inspired%20all%20over%20again%20so%20for%20me%20that%20inspiration%20was%20very%20tangible%20my%20mother%20and%20my%20grandfather%20are%20my%20grandfather%20is%20retired%20professor%20my%20mother%20is%20currently%20serving%20as%20an%20associate%20professor%20and%20I've%20been%20very%20lucky%20painting%20dogs%20record%20and%20we%20provide%20the%20source%20now%20let's%20move%20on%20to%20the%20final%20part%20let%20me%20go%20a%20little%20down%20let's%20put%20here%20I%20try%20and%20except%20block%20and%20let's%20declare%20a%20text%20that%20is%20equals%20to%20engine%20parts%20recognise%20underscore%20Google%20and%20we%20provide%20you%20after%20this%20let's%20print%20in%20the%20console%20over%20text%20and%20also%20we%20want%20to%20save%20in%20txt%20file%20so%20open%20we%20provide%20the%20name%20text%20from%20MP3%20txt%20and%20next%20we%20want%20to%20write%20the%20text%20in%20our%20new%20files%20and%20we%20provides%20the%20text%20going%20to%20exception%20block%20here%20and%20and%20don't%20forget%20that%20you%20can%20download%20the%20source%20code%20also%20don't%20forget%20to%20give%20these%20video%20like%20share%20it%20with%20your%20friends%20subscribe%20and%20activate%20the%20bell%20button%20to%20get%20notifications%20about%20new%20videos%20that%20come%20out%20and%20as%20always%20thank%20you%20for%20watching HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:13:31] \"POST /api/findSummary HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\92310\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [02/Apr/2024 00:13:32] \"POST /api/sentiment/I%20started%20my%20journey%20back%20in%202019%20after%20I%20had%20just%20graduated%20from%20fast%20and%20with%20a%20degree%20in%20Business%20Administration%20and%20I%20appeared%20in%20CSS%202020%20for%20my%20first%20attempt%20however%20I%20wasn't%20able%20to%20qualify%20the%20essay%20part%20which%20is%20why%20I%20appeared%20again%20in%20CSS%202021%20and%20fortunately%20Allah%20has%20been%20very%20kind%20to%20me%20and%20this%20time%20I%20did%20qualify%20so%20my%20Germany%20has%20also%20been%20a%20very%20long%20one%20tell%20me%20there%20is%20always%20an%20inspiration%20and%20when%20it%20comes%20to%20girls%20either%20decision%20inspiration%20of%20his%20father%20or%20mother%20what%20was%20your%20inspiration%20in%20this%20journey%20my%20inspiration%20was%20my%20grandfather%20my%20mother%20and%20my%20father%20I%20have%20with%20me%20these%20books%20that%20I%20brought%20to%20show%20that%20during%20my%20preparation%20Phase%20I%20had%20these%20three%20right%20next%20to%20my%20study%20table%20and%20I%20would%20look%20at%20them%20whenever%20times%20would%20get%20a%20for%20instance%20are%20this%20was%20the%20book%20that%20my%20mother%20purchased%20when%20she%20when%20she%20wanted%20to%20prepare%20for%20CSS%20and%20then%20these%20two%20books%20were%20purchased%20by%20my%20grandfather%20as%20you%20can%20see%20their%20very%20old%20books%20and%20this%20this%20book%20was%20published%20in%20Lucknow%20while%20this%20book%20came%20in%20the%20West%20Pakistan%20and%20these%20three%20books%20have%20kept%20me%20going%20when%20times%20got%20half%20when%20it%20was%20Difficult%20to%20move%20on%20I%20would%20just%20look%20at%20these%20books%20and%20I%20would%20just%20be%20inspired%20all%20over%20again%20so%20for%20me%20that%20inspiration%20was%20very%20tangible%20my%20mother%20and%20my%20grandfather%20are%20my%20grandfather%20is%20retired%20professor%20my%20mother%20is%20currently%20serving%20as%20an%20associate%20professor%20and%20I've%20been%20very%20lucky%20painting%20dogs%20record%20and%20we%20provide%20the%20source%20now%20let's%20move%20on%20to%20the%20final%20part%20let%20me%20go%20a%20little%20down%20let's%20put%20here%20I%20try%20and%20except%20block%20and%20let's%20declare%20a%20text%20that%20is%20equals%20to%20engine%20parts%20recognise%20underscore%20Google%20and%20we%20provide%20you%20after%20this%20let's%20print%20in%20the%20console%20over%20text%20and%20also%20we%20want%20to%20save%20in%20txt%20file%20so%20open%20we%20provide%20the%20name%20text%20from%20MP3%20txt%20and%20next%20we%20want%20to%20write%20the%20text%20in%20our%20new%20files%20and%20we%20provides%20the%20text%20going%20to%20exception%20block%20here%20and%20and%20don't%20forget%20that%20you%20can%20download%20the%20source%20code%20also%20don't%20forget%20to%20give%20these%20video%20like%20share%20it%20with%20your%20friends%20subscribe%20and%20activate%20the%20bell%20button%20to%20get%20notifications%20about%20new%20videos%20that%20come%20out%20and%20as%20always%20thank%20you%20for%20watching HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing Input........\n",
      "Converting to text........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:16:37] \"POST /api/convert-mp3-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2024 00:16:39] \"GET /api/translate_toen/hello%20again%20in%20this%20video%20we%20will%20use%20speech%20recognition%20module%20to%20extract%20text%20from%20a%20voice%20recorded%20in%20a%20MP3%20file%20the%20main%20steps%20for%20these%20are%20first%20we%20need%20to%20install%20speech%20recognition%20module%20then%20if%20you%20have%20a%20Windows%2010%20machine%20with%20Python%203.8%20like%20me%20you%20have%20also%20to%20install%20between%20module%20and%20with%20between%20you%20install%20this%20we%20can%20import%20and%20initialise%20the%20engine%20with%20MP3%20file%20and%20finally%20extract%20and%20print%20the%20text%20first%20we%20need%20to%20install%20speech%20recognition%20so%20install%20speech%20recognition%20it%20enter%20after%20this%20we%20need%20to%20install%20because%20I%20am%20using%20Windows%2010%20with%20Python%203.80%20install%20NTC%20seats%20with%20me%20close%20the%20terminal%20next%20we%20need%20to%20import%20speech%20underscore%20recognition%20AS%20or%20after%20this%20we%20want%20to%20initialise%20the%20engines%20so%20engine%20is%20equals%20to%20SR%20dot%20recognizer%20the%20next%20part%20is%20reached%20our%20MP3%20file%20let's%20go%20a%20little%20up%20because%20I%20have%20here%20a%20function%20that%20I%20created%20and%20this%20function%20generates%20using%20pyttsx3%20after%20generating%20the%20file%20it%20will%20return%20the%20name%20of%20that%20found%20is%20equals%20to%20generate%20MP3%20file%20name%20the%20source%20then%20we%20want%20to%20say%20something%20to%20the%20end%20user%20so%20we%20print%20string%20saying%20that%20the%20file%20is%20being%20analysed%20after%20painting%20dogs%20record%20and%20we%20provide%20the%20source%20now%20let's%20move%20on%20to%20the%20final%20part%20let%20me%20go%20a%20little%20down%20let's%20put%20here%20I%20try%20and%20except%20block%20and%20let's%20declare%20a%20text%20that%20is%20equals%20to%20engine%20parts%20recognise%20underscore%20Google%20and%20we%20provide%20you%20after%20this%20let's%20print%20in%20the%20console%20over%20text%20and%20also%20we%20want%20to%20save%20in%20txt%20file%20so%20open%20we%20provide%20the%20name%20text%20from%20MP3%20txt%20and%20next%20we%20want%20to%20write%20the%20text%20in%20our%20new%20files%20and%20we%20provides%20the%20text%20going%20to%20exception%20block%20here%20and%20and%20don't%20forget%20that%20you%20can%20download%20the%20source%20code%20also%20don't%20forget%20to%20give%20these%20video%20like%20share%20it%20with%20your%20friends%20subscribe%20and%20activate%20the%20bell%20button%20to%20get%20notifications%20about%20new%20videos%20that%20come%20out%20and%20as%20always%20thank%20you%20for%20watching HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2024 00:16:40] \"POST /api/analyze-audio/hello%20again%20in%20this%20video%20we%20will%20use%20speech%20recognition%20module%20to%20extract%20text%20from%20a%20voice%20recorded%20in%20a%20MP3%20file%20the%20main%20steps%20for%20these%20are%20first%20we%20need%20to%20install%20speech%20recognition%20module%20then%20if%20you%20have%20a%20Windows%2010%20machine%20with%20Python%203.8%20like%20me%20you%20have%20also%20to%20install%20between%20module%20and%20with%20between%20you%20install%20this%20we%20can%20import%20and%20initialise%20the%20engine%20with%20MP3%20file%20and%20finally%20extract%20and%20print%20the%20text%20first%20we%20need%20to%20install%20speech%20recognition%20so%20install%20speech%20recognition%20it%20enter%20after%20this%20we%20need%20to%20install%20because%20I%20am%20using%20Windows%2010%20with%20Python%203.80%20install%20NTC%20seats%20with%20me%20close%20the%20terminal%20next%20we%20need%20to%20import%20speech%20underscore%20recognition%20AS%20or%20after%20this%20we%20want%20to%20initialise%20the%20engines%20so%20engine%20is%20equals%20to%20SR%20dot%20recognizer%20the%20next%20part%20is%20reached%20our%20MP3%20file%20let's%20go%20a%20little%20up%20because%20I%20have%20here%20a%20function%20that%20I%20created%20and%20this%20function%20generates%20using%20pyttsx3%20after%20generating%20the%20file%20it%20will%20return%20the%20name%20of%20that%20found%20is%20equals%20to%20generate%20MP3%20file%20name%20the%20source%20then%20we%20want%20to%20say%20something%20to%20the%20end%20user%20so%20we%20print%20string%20saying%20that%20the%20file%20is%20being%20analysed%20after%20painting%20dogs%20record%20and%20we%20provide%20the%20source%20now%20let's%20move%20on%20to%20the%20final%20part%20let%20me%20go%20a%20little%20down%20let's%20put%20here%20I%20try%20and%20except%20block%20and%20let's%20declare%20a%20text%20that%20is%20equals%20to%20engine%20parts%20recognise%20underscore%20Google%20and%20we%20provide%20you%20after%20this%20let's%20print%20in%20the%20console%20over%20text%20and%20also%20we%20want%20to%20save%20in%20txt%20file%20so%20open%20we%20provide%20the%20name%20text%20from%20MP3%20txt%20and%20next%20we%20want%20to%20write%20the%20text%20in%20our%20new%20files%20and%20we%20provides%20the%20text%20going%20to%20exception%20block%20here%20and%20and%20don't%20forget%20that%20you%20can%20download%20the%20source%20code%20also%20don't%20forget%20to%20give%20these%20video%20like%20share%20it%20with%20your%20friends%20subscribe%20and%20activate%20the%20bell%20button%20to%20get%20notifications%20about%20new%20videos%20that%20come%20out%20and%20as%20always%20thank%20you%20for%20watching HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "127.0.0.1 - - [02/Apr/2024 00:17:03] \"POST /api/findtopic/hello%20again%20in%20this%20video%20we%20will%20use%20speech%20recognition%20module%20to%20extract%20text%20from%20a%20voice%20recorded%20in%20a%20MP3%20file%20the%20main%20steps%20for%20these%20are%20first%20we%20need%20to%20install%20speech%20recognition%20module%20then%20if%20you%20have%20a%20Windows%2010%20machine%20with%20Python%203.8%20like%20me%20you%20have%20also%20to%20install%20between%20module%20and%20with%20between%20you%20install%20this%20we%20can%20import%20and%20initialise%20the%20engine%20with%20MP3%20file%20and%20finally%20extract%20and%20print%20the%20text%20first%20we%20need%20to%20install%20speech%20recognition%20so%20install%20speech%20recognition%20it%20enter%20after%20this%20we%20need%20to%20install%20because%20I%20am%20using%20Windows%2010%20with%20Python%203.80%20install%20NTC%20seats%20with%20me%20close%20the%20terminal%20next%20we%20need%20to%20import%20speech%20underscore%20recognition%20AS%20or%20after%20this%20we%20want%20to%20initialise%20the%20engines%20so%20engine%20is%20equals%20to%20SR%20dot%20recognizer%20the%20next%20part%20is%20reached%20our%20MP3%20file%20let's%20go%20a%20little%20up%20because%20I%20have%20here%20a%20function%20that%20I%20created%20and%20this%20function%20generates%20using%20pyttsx3%20after%20generating%20the%20file%20it%20will%20return%20the%20name%20of%20that%20found%20is%20equals%20to%20generate%20MP3%20file%20name%20the%20source%20then%20we%20want%20to%20say%20something%20to%20the%20end%20user%20so%20we%20print%20string%20saying%20that%20the%20file%20is%20being%20analysed%20after%20painting%20dogs%20record%20and%20we%20provide%20the%20source%20now%20let's%20move%20on%20to%20the%20final%20part%20let%20me%20go%20a%20little%20down%20let's%20put%20here%20I%20try%20and%20except%20block%20and%20let's%20declare%20a%20text%20that%20is%20equals%20to%20engine%20parts%20recognise%20underscore%20Google%20and%20we%20provide%20you%20after%20this%20let's%20print%20in%20the%20console%20over%20text%20and%20also%20we%20want%20to%20save%20in%20txt%20file%20so%20open%20we%20provide%20the%20name%20text%20from%20MP3%20txt%20and%20next%20we%20want%20to%20write%20the%20text%20in%20our%20new%20files%20and%20we%20provides%20the%20text%20going%20to%20exception%20block%20here%20and%20and%20don't%20forget%20that%20you%20can%20download%20the%20source%20code%20also%20don't%20forget%20to%20give%20these%20video%20like%20share%20it%20with%20your%20friends%20subscribe%20and%20activate%20the%20bell%20button%20to%20get%20notifications%20about%20new%20videos%20that%20come%20out%20and%20as%20always%20thank%20you%20for%20watching HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:17:25] \"POST /api/findSummary HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\92310\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [02/Apr/2024 00:17:26] \"POST /api/sentiment/hello%20again%20in%20this%20video%20we%20will%20use%20speech%20recognition%20module%20to%20extract%20text%20from%20a%20voice%20recorded%20in%20a%20MP3%20file%20the%20main%20steps%20for%20these%20are%20first%20we%20need%20to%20install%20speech%20recognition%20module%20then%20if%20you%20have%20a%20Windows%2010%20machine%20with%20Python%203.8%20like%20me%20you%20have%20also%20to%20install%20between%20module%20and%20with%20between%20you%20install%20this%20we%20can%20import%20and%20initialise%20the%20engine%20with%20MP3%20file%20and%20finally%20extract%20and%20print%20the%20text%20first%20we%20need%20to%20install%20speech%20recognition%20so%20install%20speech%20recognition%20it%20enter%20after%20this%20we%20need%20to%20install%20because%20I%20am%20using%20Windows%2010%20with%20Python%203.80%20install%20NTC%20seats%20with%20me%20close%20the%20terminal%20next%20we%20need%20to%20import%20speech%20underscore%20recognition%20AS%20or%20after%20this%20we%20want%20to%20initialise%20the%20engines%20so%20engine%20is%20equals%20to%20SR%20dot%20recognizer%20the%20next%20part%20is%20reached%20our%20MP3%20file%20let's%20go%20a%20little%20up%20because%20I%20have%20here%20a%20function%20that%20I%20created%20and%20this%20function%20generates%20using%20pyttsx3%20after%20generating%20the%20file%20it%20will%20return%20the%20name%20of%20that%20found%20is%20equals%20to%20generate%20MP3%20file%20name%20the%20source%20then%20we%20want%20to%20say%20something%20to%20the%20end%20user%20so%20we%20print%20string%20saying%20that%20the%20file%20is%20being%20analysed%20after%20painting%20dogs%20record%20and%20we%20provide%20the%20source%20now%20let's%20move%20on%20to%20the%20final%20part%20let%20me%20go%20a%20little%20down%20let's%20put%20here%20I%20try%20and%20except%20block%20and%20let's%20declare%20a%20text%20that%20is%20equals%20to%20engine%20parts%20recognise%20underscore%20Google%20and%20we%20provide%20you%20after%20this%20let's%20print%20in%20the%20console%20over%20text%20and%20also%20we%20want%20to%20save%20in%20txt%20file%20so%20open%20we%20provide%20the%20name%20text%20from%20MP3%20txt%20and%20next%20we%20want%20to%20write%20the%20text%20in%20our%20new%20files%20and%20we%20provides%20the%20text%20going%20to%20exception%20block%20here%20and%20and%20don't%20forget%20that%20you%20can%20download%20the%20source%20code%20also%20don't%20forget%20to%20give%20these%20video%20like%20share%20it%20with%20your%20friends%20subscribe%20and%20activate%20the%20bell%20button%20to%20get%20notifications%20about%20new%20videos%20that%20come%20out%20and%20as%20always%20thank%20you%20for%20watching HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhatsApp Video 2023-12-04 at 00.26.26_d73a4a30.mp4\n",
      "MoviePy - Writing audio in uploads\\test\\WhatsApp Video 2023-12-04 at 00.26.26_d73a4a30.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:21:40] \"POST /api/convert-video-to-mp3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:22:04] \"POST /api/convert-mp4-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2024 00:22:06] \"GET /api/translate_toen/across%20the%20world%20is%20universally%20regarded%20as%20a%20great%20leader%20he%20was%20actually%20the%20son%20of%20a%20tribal%20chief%20and%20he%20was%20asked%20one%20day%20how%20did%20you%20learn%20to%20be%20a%20great%20leader%20and%20he%20responded%20that%20he%20would%20go%20with%20his%20father%20to%20Tribal%20meetings%20and%20he%20remembers%20two%20things%20when%20his%20father%20with%20me%20with%20other%20elders%20one%20they%20would%20always%20father%20was%20always HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Apr/2024 00:22:07] \"POST /api/analyze-audio/across%20the%20world%20is%20universally%20regarded%20as%20a%20great%20leader%20he%20was%20actually%20the%20son%20of%20a%20tribal%20chief%20and%20he%20was%20asked%20one%20day%20how%20did%20you%20learn%20to%20be%20a%20great%20leader%20and%20he%20responded%20that%20he%20would%20go%20with%20his%20father%20to%20Tribal%20meetings%20and%20he%20remembers%20two%20things%20when%20his%20father%20with%20me%20with%20other%20elders%20one%20they%20would%20always%20father%20was%20always HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "127.0.0.1 - - [02/Apr/2024 00:22:29] \"POST /api/findtopic/across%20the%20world%20is%20universally%20regarded%20as%20a%20great%20leader%20he%20was%20actually%20the%20son%20of%20a%20tribal%20chief%20and%20he%20was%20asked%20one%20day%20how%20did%20you%20learn%20to%20be%20a%20great%20leader%20and%20he%20responded%20that%20he%20would%20go%20with%20his%20father%20to%20Tribal%20meetings%20and%20he%20remembers%20two%20things%20when%20his%20father%20with%20me%20with%20other%20elders%20one%20they%20would%20always%20father%20was%20always HTTP/1.1\" 200 -\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 00:22:59] \"POST /api/findSummary HTTP/1.1\" 200 -\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\92310\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "127.0.0.1 - - [02/Apr/2024 00:23:00] \"POST /api/sentiment/across%20the%20world%20is%20universally%20regarded%20as%20a%20great%20leader%20he%20was%20actually%20the%20son%20of%20a%20tribal%20chief%20and%20he%20was%20asked%20one%20day%20how%20did%20you%20learn%20to%20be%20a%20great%20leader%20and%20he%20responded%20that%20he%20would%20go%20with%20his%20father%20to%20Tribal%20meetings%20and%20he%20remembers%20two%20things%20when%20his%20father%20with%20me%20with%20other%20elders%20one%20they%20would%20always%20father%20was%20always HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\", supports_credentials=True)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@app.route('/api/analyze-audio/<string:text>', methods=['POST'])\n",
    "def analyze_text(text):\n",
    "    if len(text) == 0:\n",
    "        return jsonify({'error': 'No text provided'}), 400\n",
    "    \n",
    "    doc = nlp(text) \n",
    "    person_count = len([ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]) \n",
    "    topics = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nPerson Count: {}\\n\".format(str(person_count + 1)))\n",
    "   \n",
    "    return jsonify({'person_count' : person_count + 1 , 'topic' : topics[0], 'topic2' : topics[1]})\n",
    "\n",
    "@app.route('/api/convert-video-to-mp3', methods=['POST'])\n",
    "def convert_video_to_mp3():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file provided'}), 400\n",
    "\n",
    "    video_file = request.files['file']\n",
    "    name = request.form['name']\n",
    "\n",
    "    if video_file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if video_file: \n",
    "        try:  \n",
    "            print(video_file.filename)\n",
    "            directory_path = os.path.join('uploads', name)\n",
    "            os.makedirs(directory_path, exist_ok=True) \n",
    "            video_path = os.path.join(directory_path, video_file.filename) \n",
    "            filesname, extension = os.path.splitext(video_file.filename)\n",
    "            audio_path = os.path.join(directory_path, \"{}.mp3\".format(filesname)) \n",
    "            video_file.save(video_path)\n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            audio_clip = video_clip.audio\n",
    "            audio_clip.write_audiofile(audio_path)\n",
    "            audio_clip.close()\n",
    "            video_clip.close()\n",
    "\n",
    "            return jsonify({'message': 'Video converted to MP3 successfully', 'audio_file': audio_path}), 200\n",
    "        except Exception as e:\n",
    "            return jsonify({'error': 'Conversion error', 'details': str(e)}), 500\n",
    "\n",
    "def get_audio_length(audio_filename):\n",
    "    audio = AudioSegment.from_file(audio_filename)\n",
    "    return len(audio) / 1000  # Return length in seconds    \n",
    "\n",
    "def split_audio(input_audio, output_dir, segment_length_ms=60000):\n",
    "    print(\"Proccessing Input........\") \n",
    "    audio = AudioSegment.from_file(input_audio) \n",
    "    total_length_ms = len(audio) \n",
    "    num_segments = total_length_ms // segment_length_ms \n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_time = i * segment_length_ms\n",
    "        end_time = (i + 1) * segment_length_ms\n",
    "        segment = audio[start_time:end_time] \n",
    "        segment.export(os.path.join(output_dir, f\"segment_{i}.wav\"), format=\"wav\")\n",
    "        \n",
    "    if total_length_ms % segment_length_ms > 0:\n",
    "        start_time = num_segments * segment_length_ms\n",
    "        end_time = total_length_ms\n",
    "        last_segment = audio[start_time:end_time]\n",
    "        last_segment.export(os.path.join(output_dir, f\"segment_{num_segments}.wav\"), format=\"wav\")\n",
    "\n",
    "def transcribe_audio_segments(segment_dir, lan):\n",
    "    print(\"Converting to text........\")\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    transcribed_texts = []\n",
    "    \n",
    "    for filename in os.listdir(segment_dir): \n",
    "        audio_file = os.path.join(segment_dir, filename)\n",
    "        \n",
    "        with sr.AudioFile(audio_file) as source:\n",
    "            audio_text = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_text, language=lan)\n",
    "            transcribed_texts.append(text) \n",
    "\n",
    "    return transcribed_texts\n",
    "\n",
    "def join_transcribed_texts(texts):\n",
    "    return \" \".join(texts)\n",
    "\n",
    "def convert_mp3_to_wav(mp3_filename):\n",
    "    wav_filename = mp3_filename.replace('.mp3', '.wav')\n",
    "    audio = AudioSegment.from_mp3(mp3_filename)\n",
    "    audio.export(wav_filename, format=\"wav\")\n",
    "    return wav_filename\n",
    "\n",
    "@app.route('/api/convert-mp3-to-text', methods=['POST'])\n",
    "def convert_mp3_to_text():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    language = request.form['language']\n",
    "    name = request.form['name']\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file:  \n",
    "        directory_path = os.path.join('uploads', name)\n",
    "        os.makedirs(directory_path, exist_ok=True) \n",
    "        mp3_filename = os.path.join(directory_path, file.filename)\n",
    "\n",
    "        file.save(mp3_filename) \n",
    "        segment_dir = 'segments'  \n",
    "        os.makedirs(segment_dir, exist_ok=True)\n",
    "        audio_length = get_audio_length(mp3_filename)\n",
    "\n",
    "        if audio_length > 60:\n",
    "            split_audio(mp3_filename, segment_dir, segment_length_ms=60000)\n",
    "            transcribed_texts = transcribe_audio_segments(segment_dir, language) \n",
    "            joined_text = join_transcribed_texts(transcribed_texts)\n",
    "        else:\n",
    "            recognizer = sr.Recognizer()\n",
    "\n",
    "            wav_filename = convert_mp3_to_wav(mp3_filename)\n",
    "\n",
    "            with sr.AudioFile(wav_filename) as source:\n",
    "                audio_text = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio_text, language=language)\n",
    "                joined_text = text\n",
    "\n",
    "        filesname, extension = os.path.splitext(file.filename)\n",
    "        text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "\n",
    "        with open(text_path, 'w') as fil:\n",
    "            fil.write(\"Converted Text: \" + joined_text + \"\\n\")\n",
    "\n",
    "        return jsonify({'text': joined_text})\n",
    "\n",
    "\n",
    "@app.route('/api/convert-mp4-to-text', methods=['POST'])\n",
    "def convert_mp4_to_text():\n",
    "    language = request.form['language']\n",
    "    file = request.files['file']\n",
    "    name = request.form['name']\n",
    "\n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "\n",
    "    file = os.path.abspath('./uploads/{}/{}.mp3'.format(name, filesname)) \n",
    "\n",
    "    if file: \n",
    "        mp3_filename = file\n",
    "        wav_filename = mp3_filename.replace('.mp3', '.wav') \n",
    "        AudioSegment.from_mp3(mp3_filename).export(wav_filename, format=\"wav\")\n",
    "\n",
    "    segment_dir = 'segments'\n",
    "    try:\n",
    "        if not os.path.exists(segment_dir):\n",
    "            os.mkdir(segment_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory: {e}\")\n",
    "\n",
    "    audio_length = get_audio_length(mp3_filename)\n",
    "\n",
    "    if audio_length > 60: \n",
    "        split_audio(wav_filename, segment_dir, segment_length_ms=60000)  \n",
    "        transcribed_texts = transcribe_audio_segments(segment_dir,lan=language)  \n",
    "        joined_text = join_transcribed_texts(transcribed_texts) \n",
    "    else:\n",
    "        recognizer = sr.Recognizer() \n",
    "        \n",
    "        with sr.AudioFile(wav_filename) as source:\n",
    "            audio_text = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_text, language=language)\n",
    "            joined_text = text\n",
    "\n",
    "    directory_path = os.path.join('uploads', name)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname)) \n",
    "\n",
    "    with open(text_path, 'w') as fil:\n",
    "        fil.write(\"Converted Text: \" + joined_text + \"\\n\")\n",
    "\n",
    "    return jsonify({'text': joined_text})\n",
    "\n",
    "\n",
    "@app.route('/api/translate_toar/<string:text>', methods=['GET'], endpoint='translate_to_ar')\n",
    "def translate_to_ar(text):    \n",
    "    translator = Translator() \n",
    "    arabic_translation = translator.translate(text,  src='auto', dest='ar').text\n",
    "    return jsonify({'translated_txt': arabic_translation})\n",
    "\n",
    "@app.route('/api/translate_totr/<string:text>', methods=['GET'], endpoint='translate_to_tr')\n",
    "def translate_to_tr(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    turkish_translation = translator.translate(text, src='auto', dest='tr').text\n",
    "    return jsonify({'translated_txt': turkish_translation})\n",
    "\n",
    "@app.route('/api/translate_toen/<string:text>', methods=['GET'], endpoint='translate_to_en')\n",
    "def translate_to_en(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    english_translation = translator.translate(text, src='auto', dest='en').text\n",
    "    return jsonify({'translated_txt': english_translation})\n",
    "\n",
    "@app.route('/api/translate_tohi/<string:text>', methods=['GET'], endpoint='translate_to_hi')\n",
    "def translate_to_hi(text):  \n",
    "    translator = Translator()    \n",
    "\n",
    "    hindi_translation = translator.translate(text, src='auto', dest='hi').text\n",
    "    return jsonify({'translated_txt': hindi_translation})\n",
    "\n",
    "def add_newlines_every_n_words(input_string, n=10):\n",
    "    words = input_string.split()\n",
    "    output_string = ''\n",
    "    for i, word in enumerate(words):\n",
    "        if i > 0 and i % n == 0:\n",
    "            output_string += '\\n'\n",
    "        output_string += word + ' '\n",
    "    return output_string.strip()\n",
    "\n",
    "@app.route('/api/findtopic/<string:text>', methods=['POST'])\n",
    "def topic_finder(text):\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
    "    pipe2 = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "\n",
    "    topic = pipe(text)  \n",
    "    topic = topic[0]['label']\n",
    "\n",
    "    topic2 = pipe2(text, max_length = 10)\n",
    "    topic2 = topic2[0]['summary_text']\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nTopic: {}\\n\".format(topic2))\n",
    "    \n",
    "    return jsonify({'topic': topic, 'topic2': topic2})\n",
    "\n",
    "@app.route('/api/findSummary', methods=['POST'])\n",
    "def summary_find():\n",
    "    text = request.form['text']\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    \n",
    "    temp = add_newlines_every_n_words(text, 30)\n",
    "    try: \n",
    "        summary = summarize(temp)\n",
    "        print(\"len: \", len(summary))\n",
    "    except:\n",
    "        print(\"Error in summarization using gensim\") \n",
    "        summary = \"\"\n",
    "\n",
    "    if len(summary) == 0:\n",
    "        output = pipe(text) \n",
    "        summary = output[0]['summary_text']\n",
    "             \n",
    "    translator = Translator() \n",
    "    arabic_summary = translator.translate(summary, src='en', dest='ar').text\n",
    "    turkish_summary = translator.translate(summary, src='en', dest='tr').text\n",
    "\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nSummary: {}\\n\".format(str(summary)))\n",
    "\n",
    "    return jsonify({'summary_en': str(summary), 'summary_ar': arabic_summary, 'summary_tr': turkish_summary})\n",
    "\n",
    "@app.route('/api/sentiment/<string:text>', methods=['POST'])\n",
    "def sentiment(text):\n",
    "    name = request.form['name']\n",
    "    file = request.files['file']\n",
    "\n",
    "    nltk.download('vader_lexicon')\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    positive_percent = round(scores['pos'] * 100, 2)\n",
    "    negative_percent = round(scores['neg'] * 100, 2)\n",
    "\n",
    "    total = positive_percent + negative_percent\n",
    "    fin_pos = round((positive_percent/total)*100, 2)\n",
    "    fin_neg = round((negative_percent/total)*100, 2) \n",
    "\n",
    "    directory_path = os.path.join('uploads', name) \n",
    "    filesname, extension = os.path.splitext(file.filename)\n",
    "    text_path = os.path.join(directory_path, \"{}.txt\".format(filesname))  \n",
    "\n",
    "    with open(text_path, 'a') as fil:\n",
    "        fil.write(\"\\nPositive Sentiment: {}% \\nNegative Sentiment: {}%\".format(fin_pos, fin_neg))\n",
    "\n",
    "    return jsonify({'positive': fin_pos, 'negative': fin_neg})\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Obtaining dependency information for tf-keras from https://files.pythonhosted.org/packages/75/aa/cf09f8956d4f276f655b13674e15d8d6015fd832f9689aa9ff2a515781ab/tf_keras-2.16.0-py3-none-any.whl.metadata\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.1.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\92310\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 262.6 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.1/1.7 MB 328.2 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.1/1.7 MB 438.1 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.1/1.7 MB 437.6 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.7 MB 473.7 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.7 MB 473.7 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.3/1.7 MB 605.3 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.3/1.7 MB 609.2 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.3/1.7 MB 553.0 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.4/1.7 MB 637.7 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.4/1.7 MB 638.9 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/1.7 MB 688.0 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 685.6 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.5/1.7 MB 727.4 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.6/1.7 MB 721.1 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.6/1.7 MB 766.8 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.7/1.7 MB 784.1 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.7/1.7 MB 791.2 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.8/1.7 MB 816.6 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 0.8/1.7 MB 817.2 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.9/1.7 MB 841.9 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.7 MB 849.5 kB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 865.7 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.7 MB 876.7 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.1/1.7 MB 884.7 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.1/1.7 MB 884.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.7 MB 859.0 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.2/1.7 MB 901.1 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.7 MB 873.9 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.4/1.7 MB 894.3 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.4/1.7 MB 887.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.4/1.7 MB 899.9 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.7 MB 905.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.5/1.7 MB 910.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.6/1.7 MB 929.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.7 MB 925.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 937.9 kB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
